#  Script to rum STE for abudance estimates using varying sample window lengths and generating 
#   multiple STE data sets from single inputs of camera-trap records and deployment info. Bayesian
#  implementation and ML implementation shown. Viisualize and summarise outpus.


library(dplyr)
library(sf)
library(spaceNtime)
library(tictoc)
library(doParallel)

setwd("D:/Puma/Torres_del_Paine/STE")



################################################################################
#  Observation (photo) records
df <- readr::read_csv("Puma.csv")

# Camera deployment data; area column is in sq m
deploy <- readr::read_csv("Camera_Deploy_3_final_firstseason.csv")
deploy$area <- 0.000023 # viewshed area in sq km

#  Specify the sampling occasions with function build_occ()
study_dates <- as.POSIXct(c("2019-05-19 12:03:00", "2019-09-13 18:14:00"), tz = "America/Punta_Arenas")



################################################################################
#  Example STE run for a single data set
occ <- build_occ(samp_freq = 60, # seconds between the start of each sampling occasion
    samp_length = 2, # duration of each sampling occasion (seconds)
    study_start = study_dates[1],
    study_end = study_dates[2])

#  EH: There will be an NA on every occasion where no animals were detected. 
#   The model will treat these NAs as right-censors.     
ste_eh <- ste_build_eh(df, deploy, occ)

ste_eh[1:3,]
tst <- ste_eh$STE
length(tst) # 168851 rows in EH
tst[!is.na(tst)] <- 1
sum(tst, na.rm = TRUE) # 67 detections

#  Estimate N: population expected in the study area; calculated as lambda * study area size.
#  lambda is is average density per sq m (only parameter estimated by model)
#  Study area can be any value want to know; here I specify 100,000,000 sq m (aka 100 sq km)

ste_estN_fn(ste_eh, study_area = 100)



################################################################################
#  Loops to generate data sets by shifting start time by 1 second and using multiple sample 
#  window lengths
#  Bayesian implementation via Metropolis Hastings MCMC sampler with 3 chains


# Sample window lengths to investigate
samp_ls <- c(2, 4, 6, 8, 10)

# Sample frequency (e.g., every 180 seconds)
samp_f <- 180 

# Seconds shift start time for generating multiple data sets
shift <- 1


# List to hold ouptuts
full_out_ls <- list()

# Loop across sample window lenghts
for(k in 1:length(samp_ls)){

	# Parallel processing
	registerDoParallel(cl <- makeCluster(20))

	samp_l <- samp_ls[k]
	print(samp_l[k])

	
	#  Loop across multiple data sets generated by shifting start time
	out_ls <- foreach(i = 0:((samp_f/shift)-1), .packages = c("spaceNtime", "dplyr")) %do% {

		tmp <- build_occ(samp_freq = samp_f, # seconds between the start of each sampling occasion
			samp_length = samp_l, # duration of each sampling occasion (seconds)
			study_start = (study_dates[1] + i*shift),
			study_end = study_dates[2])

		ste_eh <- ste_build_eh(df, deploy, tmp)
		tst <- ste_eh$STE
		tst[!is.na(tst)] <- 1
		tst2 <- sum(tst, na.rm = TRUE) 

		if(tst2 == 0){
			
			out <- data.frame(N = NA, SE = NA, LCI  = NA, UCI = NA)
			
			}else{
			   
				
				# Bayesian implementation of STE
				#  Set up MCMC algorithm
				nReps <- 5000		# number of MCMC reps
				dat <- list(toevent = matrix(ste_eh$STE, nrow = 1), censor = ste_eh$censor)
				opt <- suppressWarnings(stats::optim(log(1/mean(dat$toevent, 
					na.rm = T)), exp_logl_fn, x = dat, control = list(fnscale = -1), 
					hessian = T))
				old.p <- log(1/mean(dat$toevent,  na.rm = T))		# initial value for p (arbitrary)
				res <- matrix(NA, nReps, 2)		# create a matrix to hold the results
				colnames(res) <- c( "log_lambda", "Deviance")			# name the columns of the matrix
				old.logPost <- spaceNtime::exp_logl_fn(dat, old.p) + dnorm(old.p, 0, 10, log=TRUE)		# compute the log-Posterior for the initial p (logLike+logPrior)

				# Main MCMC loop
				for(i in 1:nReps){	
					
					new.p <- rnorm(1, opt$par, sqrt(-MASS::ginv(opt$hessian))*2 )		# draw a candidate value for p
					new.logPost <- spaceNtime::exp_logl_fn(dat, new.p) + 
						dnorm(new.p, 0, 10, log=TRUE)		# compute the log-Posterior for the new p
					logR <- new.logPost - old.logPost		# calculate the log-R ratio
					
					if(runif(1) < exp( logR )){		# exponentiate R and compare to a U(0,1) random number
						res[i,1] <- new.p		# keep new p if random number < R
						res[i,2] <- -2*new.logPost		# calculate deviance and store

						old.p <- new.p		# update the stored value for p
						old.logPost <- new.logPost		# update the stored value for logPost
						}else{		# reject new p if random number > R
							
							res[i,1] <- old.p		# store p
							res[i,2] <- -2*old.logPost		# store deviance
							}
						
					}
				
				#  Output for a sinlge data set; remove first 1000 iterations as burn-in
				res_df <- res[1000:nReps,] %>%
					as.data.frame() %>%
					mutate(lambda = exp(log_lambda)) %>%
					mutate(Dens_100sqkm = lambda * 100)
				
				#  Store mean, SE, LCI and UCI of MCMC iteratoins (minus burn-in)
				out <- data.frame(
					N = mean(res_df$Dens_100sqkm), 
					SE = sd(res_df$Dens_100sqkm)/nrow(res_df), 
					LCI  = HDInterval::hdi(res_df)[1,4], 
					UCI = HDInterval::hdi(res_df)[2,4])
				}
				
			return(out)
			}

	stopCluster(cl)

	#  Save outputs from all generated data sets for given sample window length
	full_out <- do.call(rbind, out_ls) %>%
		mutate(samp_freq = paste(samp_f),
			samp_len = paste(samp_l),
			start_shift = paste(shift)) 
			
	full_out_ls[k] <- full_out
	}



################################################################################
#  Ran in batches on MAC to improve speed
#  Combine runs
load("full_out_ls_246.Rdata")
out2s <-  data.frame(Dens_100sqkm =  full_out_ls[[1]]) %>%
		mutate(samp_freq = 180,
			samp_len = 2) 
out4s <-  data.frame(Dens_100sqkm =  full_out_ls[[2]]) %>%
		mutate(samp_freq = 180,
			samp_len = 4) 			
out6s <-  data.frame(Dens_100sqkm =  full_out_ls[[3]]) %>%
		mutate(samp_freq = 180,
			samp_len = 6) 		

load("full_out_8l.Rdata")			
out8s <- full_out %>%
	dplyr::select(Dens_100sqkm = N, samp_freq, samp_len)

load("full_out_10l.Rdata")
out10s <- full_out %>%
	dplyr::select(Dens_100sqkm = N, samp_freq, samp_len)

out <- out2s %>%
	rbind(out4s) %>%
	rbind(out6s) %>%
	rbind(out8s) %>%
	rbind(out10s) 
out$samp_len <- as.numeric(out$samp_len)
out$samp_freq <- as.numeric(out$samp_freq)


	
################################################################################
#  Generate summary statistics for each sample window length	
overall_lower10_Dens_100sqkm <- quantile(out$Dens_100sqkm, na.rm = TRUE, probs = c(0.1))
overall_upper90_Dens_100sqkm <- quantile(out$Dens_100sqkm, na.rm = TRUE, probs = c(0.9))
	
out_sm <-  out  %>% 
	group_by(samp_len) %>% 
	summarize(mean_Dens_100sqkm = mean(Dens_100sqkm, na.rm = TRUE), 
		sd_Dens_100sqkm = sd(Dens_100sqkm, na.rm = TRUE),
		lower2.5_Dens_100sqkm = quantile(Dens_100sqkm, na.rm = TRUE, probs = c(0.025)),
		upper97.5_Dens_100sqkm = quantile(Dens_100sqkm, na.rm = TRUE, probs = c(0.975))) %>%
	as.data.frame() %>%
	mutate(change_dens = (mean_Dens_100sqkm - lag(mean_Dens_100sqkm))/lag(mean_Dens_100sqkm))
out_sm$samp_len <- as.numeric(out_sm$samp_len)



################################################################################
#  Visualizations

# Make "dead bee" dots for data sets that had no observations so could not generate an
# abundance estimate
dead_bees <- data.frame(samp_len = c(rep(2, 50), 
	rep(4, 26), rep(6, 12), rep(8, 2)), dead_bee = rep(-0.1, (50 + 26 + 12 + 2)))


p1 <- ggplot() +
	geom_jitter(data = out, 
		aes(x = factor(samp_len),
			y = Dens_100sqkm), 
			size = 2, alpha = 0.15, 
		#color = "#FF0000", width = 0.25) +
		color = "black", width = 0.25) +
	geom_errorbar(data = out_sm, 
		aes(x = factor(samp_len), 
			ymin = mean_Dens_100sqkm - sd_Dens_100sqkm, 
			ymax = mean_Dens_100sqkm + sd_Dens_100sqkm), 
		color = "grey10", size = 1, width = 0.175) +
	geom_point(data = out_sm, 
		aes(x = factor(samp_len), 
			y = mean_Dens_100sqkm), 
		color = "grey10", size = 4) +
	geom_jitter(data = dead_bees, 
		aes(x = factor(samp_len), 
			y = dead_bee), width = 0.1, height = 0,
		color = "blue", size = 2, shape = "|") +
	theme_bw() +
	ylab("Density (per 100 sq. km.)") +
	xlab("Sample length (sec)") +
	scale_y_continuous(minor_breaks = seq(0, 20, 1), 
		limits = c(-0.1, 20),
		breaks = c(0, 5, 10, 15, 20)) +
	theme(text = element_text(size = 14)) +
	geom_hline(yintercept = 0, color = "grey70")	+
	geom_hline(yintercept = 5.070, linetype = "longdash", 
		size = 0.9, col = "#FF0000")  #gSPIM corrected density mean
	
p1
#ggsave("Figures/varying_sample_lengths_MCMC.png")


p2 <- ggplot() +
	#geom_histogram(data = out, bins = 10,
		#aes(x = Dens_100sqkm), 
		#colour = "black",	fill = "grey50") +
	geom_density(data = out, 
		aes(x = Dens_100sqkm), alpha = 0.7,
		colour = "black", fill = "grey50") +
	theme_bw() +
	xlab("Density (per 100 sq. km.)") +
	ylab("Frequency") +
	scale_x_continuous(limits = c(0, 18),
		breaks = seq(0,18, by = 2)) +
	theme(text = element_text(size = 14)) +
	geom_vline(xintercept = 5.070, linetype = "longdash", 
		size = 0.9, color = "darkred") #gSPIM corrected density mean
p2
#ggsave("Figures/all_MCMC_estimates.png")
#ggsave("Figures/all_MCMC_estimates_dens.png")


p1a <- ggplot() +
	geom_jitter(data = out, 
		aes(x = factor(samp_len),
			y = Dens_100sqkm), 
			size = 2, alpha = 0.15, 
		#color = "#FF0000", width = 0.25) +
		color = "black", width = 0.25) +
	geom_errorbar(data = out_sm, 
		aes(x = factor(samp_len), 
			ymin = mean_Dens_100sqkm - sd_Dens_100sqkm, 
			ymax = mean_Dens_100sqkm + sd_Dens_100sqkm), 
		color = "grey10", size = 1, width = 0.175) +
	geom_point(data = out_sm, 
		aes(x = factor(samp_len), 
			y = mean_Dens_100sqkm), 
		color = "grey10", size = 4) +
	theme_bw() +
	ylab("Density (per 100 sq. km.)") +
	xlab("Sample length (sec)") +
	scale_y_continuous(minor_breaks = seq(0, 20, 1), 
		limits = c(0, 20),
		breaks = c(0, 5, 10, 15, 20)) +
	theme(text = element_text(size = 14)) +
	geom_hline(yintercept = 0, color = "grey70")	+
	geom_hline(yintercept = 5.070, linetype = "longdash", 
		size = 0.9, col = "#FF0000")  #gSPIM corrected density mean
	
p1a
#ggsave("Figures/varying_sample_lengths_MCMC.png")


p1inset <- ggplot() +
	geom_point(data = out, 
		aes(x = factor(samp_len),
			y = Dens_100sqkm), 
			size = 2, alpha = 0.15, color = "black") +
	theme_bw() +
	ylab("Density (per 100 sq. km.)") +
	xlab("Sample length (sec)") +
	scale_y_continuous(minor_breaks = seq(0,10, 1), 
		limits = c(-0.1, 10),
		breaks = seq(0, 10, 1)) +
	theme(text = element_text(size = 14)) +
	geom_hline(yintercept = 0, color = "grey70")
p1inset



################################################################################
# Summary stats

samp_f <- 180
shift <- 1

res2 <- data.frame()
for(i in 0:((samp_f/shift)-1)){
	tmp <- build_occ(samp_freq = 180,
		samp_length = 2,
		study_start = (study_dates[1] + i*shift),
		study_end = study_dates[2])
	ste_eh <- ste_build_eh(df, deploy, tmp)
	tst <- ste_eh$STE
	tst[!is.na(tst)] <- 1
	tst2 <- sum(tst, na.rm = TRUE) 
	tst3 <- first(which(ste_eh$STE != "NA"))

	res_tmp <- data.frame(samp_l = 2,
		n_occ = nrow(ste_eh),
		det = tst2,
		dataset = i, 
		frst_det = tst3)
	res2 <- res2 %>%
		rbind(res_tmp)
	}

res4 <- data.frame()
for(i in 0:((samp_f/shift)-1)){
	tmp <- build_occ(samp_freq = 180,
		samp_length = 4,
		study_start = (study_dates[1] + i*shift),
		study_end = study_dates[2])
	ste_eh <- ste_build_eh(df, deploy, tmp)
	tst <- ste_eh$STE
	tst[!is.na(tst)] <- 1
	tst2 <- sum(tst, na.rm = TRUE) 
	tst3 <- first(which(ste_eh$STE != "NA"))

	res_tmp <- data.frame(samp_l = 4,
		n_occ = nrow(ste_eh),
		det = tst2,
		dataset = i, 
		frst_det = tst3)
	res4 <- res4 %>%
		rbind(res_tmp)
	}
	
res6 <- data.frame()
for(i in 0:((samp_f/shift)-1)){
	tmp <- build_occ(samp_freq = 180,
		samp_length = 6,
		study_start = (study_dates[1] + i*shift),
		study_end = study_dates[2])
	ste_eh <- ste_build_eh(df, deploy, tmp)
	tst <- ste_eh$STE
	tst[!is.na(tst)] <- 1
	tst2 <- sum(tst, na.rm = TRUE) 
	tst3 <- first(which(ste_eh$STE != "NA"))
	
	res_tmp <- data.frame(samp_l = 6,
		n_occ = nrow(ste_eh),
		det = tst2,
		dataset = i, 
		frst_det = tst3)
	res6 <- res6 %>%
		rbind(res_tmp)
	}

res8 <- data.frame()
for(i in 0:((samp_f/shift)-1)){
	tmp <- build_occ(samp_freq = 180,
		samp_length = 8,
		study_start = (study_dates[1] + i*shift),
		study_end = study_dates[2])
	ste_eh <- ste_build_eh(df, deploy, tmp)
	tst <- ste_eh$STE
	tst[!is.na(tst)] <- 1
	tst2 <- sum(tst, na.rm = TRUE) 
	tst3 <- first(which(ste_eh$STE != "NA"))

	res_tmp <- data.frame(samp_l = 8,
		n_occ = nrow(ste_eh),
		det = tst2,
		dataset = i, 
		frst_det = tst3)
	res8 <- res8 %>%
		rbind(res_tmp)
	}

res10 <- data.frame()
for(i in 0:((samp_f/shift)-1)){
	tmp <- build_occ(samp_freq = 180,
		samp_length = 10,
		study_start = (study_dates[1] + i*shift),
		study_end = study_dates[2])
	ste_eh <- ste_build_eh(df, deploy, tmp)
	tst <- ste_eh$STE
	tst[!is.na(tst)] <- 1
	tst2 <- sum(tst, na.rm = TRUE) 
	tst3 <- first(which(ste_eh$STE != "NA"))

	res_tmp <- data.frame(samp_l = 10,
		n_occ = nrow(ste_eh),
		det = tst2,
		dataset = i, 
		frst_det = tst3)
	res10 <- res10 %>%
		rbind(res_tmp)
	}



# ##############################################################################
# #  ALTERNATIVE; Maximum likelihood implementation using only 'spaceNtime' package

# #  Function to run various sample window lengths
# samp_f <- 180
# shift <- 1

# ste_rep <- function(samp_f = samp_f, samp_l = samp_l, shift = shift){

    # out_ls <- list()

    # for(i in 0:((samp_f/shift)-1)){

        # print(i)

        # tmp <- build_occ(samp_freq = samp_f, # seconds between the start of each sampling occasion
            # samp_length = samp_l, # duration of each sampling occasion (seconds)
            # study_start = (study_dates[1] + i*shift),
            # study_end = study_dates[2])

        # ste_eh <- ste_build_eh(df, deploy, tmp)
        # tst <- ste_eh$STE
        # tst[!is.na(tst)] <- 1
        # tst2 <- sum(tst, na.rm = TRUE) 
		# tst3 <- first(which(ste_eh$STE != "NA"))

        # if(tst2 == 0){
            # out <- data.frame(N = NA, SE = NA, LCI  = NA, UCI = NA)
            # }else{
                # out <- ste_estN_fn(ste_eh, study_area = 100)
                # }

        # out_ls[[i+1]] <- out
        # rm(tmp, ste_eh, out)
        # }

    # res <- do.call(rbind, out_ls) %>%
		# mutate(samp_freq = paste(samp_f),
			# samp_len = paste(samp_l),
			# start_shift = paste(shift),
			# n_det = tst2,
			# first_det = tst3) 
    # return(res)

    # }



# out_180f_2l_1s <- ste_rep(samp_f = 180, samp_l = 2, shift = 1)
# out_180f_4l_1s <- ste_rep(samp_f = 180, samp_l = 4, shift = 1)
# out_180f_6l_1s <- ste_rep(samp_f = 180, samp_l = 6, shift = 1)
# out_180f_8l_1s <- ste_rep(samp_f = 180, samp_l = 8, shift = 1)
# out_180f_10l_1s <- ste_rep(samp_f = 180, samp_l = 10, shift = 1)


# out_all_samp_l <- out_180f_2l_1s %>% 
	# rbind(out_180f_4l_1s) %>% 
	# rbind(out_180f_6l_1s) %>% 
	# rbind(out_180f_8l_1s) %>% 
	# rbind(out_180f_10l_1s) 
# out_all_samp_l$samp_len <- as.numeric(out_all_samp_l$samp_len)
# out_all_samp_l$samp_freq <- as.numeric(out_all_samp_l$samp_freq)
	
# out_all_samp_l_summ <- out_all_samp_l  %>% 
	# group_by(samp_len) %>% 
	# summarize(mean_N = mean(N, na.rm = TRUE), 
	# sd_N = sd(N, na.rm = TRUE),
	# min_N = min(N, na.rm = TRUE),
	# max_N = max(N, na.rm = TRUE),
	# p10_N = quantile(N, probs = 0.1, na.rm = TRUE),
	# p90_N = quantile(N, probs = 0.9, na.rm = TRUE))


# out_all_samp_l_summ$samp_len <- as.numeric(out_all_samp_l_summ$samp_len)


# p <- ggplot() +
	# geom_jitter(data = out_all_samp_l , aes(x = factor(samp_len), y = N), size = 2, alpha = 0.15, 
		# color = "#FF0000", width = 0.25) +
	# geom_errorbar(data = out_all_samp_l_summ, 
		# aes(x = factor(samp_len), ymin = mean_N - sd_N, ymax = mean_N + sd_N), 
		# color = "grey10", size = 1.25, width = 0.2) +
	# geom_point(data = out_all_samp_l_summ, aes(x = factor(samp_len), y = mean_N), 
		# color = "grey10", size = 6, shape = 15) +
	# theme_bw() +
	# ylab("Density (per 100 sq. km.)") +
	# xlab("Sample window length (sec)") +
	# scale_y_continuous(minor_breaks = seq(0, 20, 1), 
		# limits = c(0, 20),
		# breaks = c(0, 5, 10, 15, 20)) +
	# theme(text = element_text(size = 14)) 
# p

# #ggsave("Figures/varying_sample_lengths.png")


##############################################################################
##############################################################################
